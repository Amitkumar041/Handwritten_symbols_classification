{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d7fea06",
   "metadata": {},
   "source": [
    "## Train File Using VGG-16 Model for Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e9a304",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b68c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Activation, MaxPooling2D, BatchNormalization, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import math\n",
    "import numpy.random as npr\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dcceb9",
   "metadata": {},
   "source": [
    "### Code for checking for GPU built with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af9d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available 1\n",
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available\", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.test.is_built_with_cuda()\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c8ec279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data,labels,learning_rate = 0.01, steps_per_epoch =10,epochs = 100, patience = 10):\n",
    "    \n",
    "    ###########################################################################################################################\n",
    "    #Cretes directory and file structure for CNN training\n",
    "    ###########################################################################################################################\n",
    "    '''A directory structure is created where files euqal to the number of classes are created inside the main directory.\n",
    "       This file structure is necessary to generate trainable dataset using ImageDatagenerator. Where the name of each file \n",
    "       in the directory is the name of each classes in the dataset.\n",
    "    '''\n",
    "    # gets path of current directory\n",
    "    cwd = os.getcwd()                                           \n",
    "    if os.path.exists(cwd+'/sosimple_data') == False :\n",
    "        # create a directory as given path and of given name\n",
    "        os.mkdir(cwd+'/sosimple_data')                          \n",
    "\n",
    "    for i in range(10):\n",
    "        if os.path.exists(cwd+'/sosimple_data/'+ str(i)) == False: \n",
    "            # create a directory as given path and of given nam\n",
    "            os.mkdir(cwd+'/sosimple_data/'+ str(i))\n",
    "            \n",
    "    ###########################################################################################################################\n",
    "    # Convert to image and save in directory sosimple_data\n",
    "    ###########################################################################################################################\n",
    "    '''The data from .npy file of the image data is converted into .png image format and then saved into the respective directory\n",
    "       according to the classes they have. Each image of same class is saved into same file into the main class.'''\n",
    "    \n",
    "    # Loads numpy file from the given path \n",
    "    data_train_t = np.load(train_data)                                   \n",
    "    labels_train_t = np.load(labels)\n",
    "    \n",
    "    labels_names = ['x','square root','plus sign','negative sign',\n",
    "                'equal','percent','partial','product','pi','summation']\n",
    "    \n",
    "    \n",
    "    def class_convert_to_image(label, X, t, class_names, figsize=(15,150)): \n",
    "\n",
    "        # Index locations where class label stored in data_train\n",
    "        sample_idx = np.where(t==label)[0] \n",
    "\n",
    "        #Number of samples in class label\n",
    "        N = len(sample_idx)\n",
    "\n",
    "        for i in range(N):\n",
    "            imgname = str(label)+'_'+str(i)\n",
    "            save_path = os.path.join(cwd+'/sosimple_data/',str(label),imgname+\".png\")\n",
    "            plt.imsave(save_path,X[:,sample_idx[i]].reshape(300,300), cmap='gray')\n",
    "        print(\"finished\")\n",
    "   \n",
    "    # Converts array into images and saves them into there respective class files.\n",
    "    for i in range(0,10):\n",
    "        class_convert_to_image(i, data_train_t, labels_train_t, labels_names)\n",
    "    \n",
    "    ###########################################################################################################################\n",
    "    # Pre-processing and input of image data from directory\n",
    "    ###########################################################################################################################\n",
    "    #gets the loaction of directory were imgae file are saved.\n",
    "    train_dir = cwd +\"/sosimple_data\"\n",
    "    \n",
    "    # Used for data augmentation and preprocessing\n",
    "    train_datagen = ImageDataGenerator(validation_split = 0.3) ## Converts the image files into a format that can be used to train \n",
    "                                                               ## CNN models also can be used for data augmentaion like rotate,shear\n",
    "                                                               ## zoom,etc. Also splits data into train and validation split\n",
    "    \n",
    "    train_data = train_datagen.flow_from_directory(directory = train_dir,  ## Gets the data form the directory, used for image\n",
    "                                                   target_size = (100,100),## preprocessing and divides the data into bacthes .\n",
    "                                                   batch_size = 24,\n",
    "                                                   subset='training')\n",
    "    test_data = train_datagen.flow_from_directory(directory = train_dir, \n",
    "                                                  target_size = (100,100),\n",
    "                                                  batch_size = 24,\n",
    "                                                  subset='validation')\n",
    "    ###########################################################################################################################\n",
    "    # VGG -16 Model\n",
    "    ###########################################################################################################################\n",
    "    model = Sequential()\n",
    "    # 1st Convolution Layer\n",
    "    model.add(Conv2D(input_shape=(100,100,3), filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # 2nd Convolution layer\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3),padding='same', activation='relu'))\n",
    "    # 3rd Pooling Layer\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    # 4th Convolution Layer\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # 5th Convolution layer\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # 6th Pooling layer\n",
    "    model.add(MaxPooling2D(strides=(2,2), pool_size=(2,2)))\n",
    "    # 7th Convolution layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # 8th Convolution layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # 9th Convolution layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # 10th Pooling Layer\n",
    "    model.add(MaxPooling2D(strides=(2,2), pool_size=(2,2)))\n",
    "    # 11th Convolution layer\n",
    "    model.add(Conv2D(filters= 512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # 12th Conv layer\n",
    "    model.add(Conv2D(filters= 512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # 13th Conv layer\n",
    "    model.add(Conv2D(filters= 512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # 14th Pooling Layer \n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    # 15th Convolution layer\n",
    "    model.add(Conv2D(filters= 512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # 16th Conv layer\n",
    "    model.add(Conv2D(filters= 512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # 17th Conv layer\n",
    "    model.add(Conv2D(filters= 512, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    # 18th Pooling Layer \n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.summary()\n",
    "    \n",
    "    ############################################################################################################################\n",
    "    # Model Checkpoints\n",
    "    ############################################################################################################################\n",
    "    mc = ModelCheckpoint(filepath=\"./train_model.h5\", ## creates a checkpoint so that it can be used to train the data from were\n",
    "                     monitor = \"val_accuracy\",         ## it stoped rather than just training it again from scratch also helps\n",
    "                     verbose = 1,                      ## save weights of the model.\n",
    "                     save_best_only = \"True\")\n",
    "    es = EarlyStopping(monitor = \"val_accuracy\",           ## Used to stop training the model if there is no progress in given metric\n",
    "                       min_delta = 0.01,                   ## helps avoid overfitting and better control of data\n",
    "                       patience = patience,\n",
    "                       verbose = 1)\n",
    "    cb = [mc,es]\n",
    "\n",
    "    \n",
    "    ############################################################################################################################\n",
    "    # Model Compilation\n",
    "    ############################################################################################################################\n",
    "    opt = SGD(learning_rate=learning_rate) ## Stocastic Gradient Descent this works better with VGG16 alos learning rate is hypeparameter\n",
    "    model.load_weights('./train_model.h5') ## Loading the weights from the eposchs with best validation accuracy\n",
    "    model.compile( optimizer=opt, loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])##compiling the model for training\n",
    "    \n",
    "    ##############################################################################################################################\n",
    "    #Model training\n",
    "    ###############################################################################################################################\n",
    "    \n",
    "    his = model.fit_generator(train_data,steps_per_epoch = steps_per_epoch , epochs= epochs , validation_data=test_data, callbacks = cb)\n",
    "    \n",
    "    ################################################################################################################################\n",
    "    # Visualization of model performance\n",
    "    ################################################################################################################################\n",
    "    \n",
    "    # loads the model and its weights along with all the epoches information in latest traiing\n",
    "    model = load_model(\"./train_model.h5\")\n",
    "    h = his.history\n",
    "    plt.plot(h['loss'], c = \"red\")\n",
    "    plt.plot(h['val_loss'],'go--', c = \"red\")\n",
    "    plt.plot(h['accuracy'], c = \"blue\")\n",
    "    plt.plot(h['val_accuracy'],'go--', c = \"blue\")\n",
    "\n",
    "    plt.title(\"Loss vs accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb644c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_t = 'data_train_correct.npy'\n",
    "labels_train_t = 'labels_train_corrected.npy'\n",
    "train(data_train_t, labels_train_t,0.01,10,100,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c70e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
